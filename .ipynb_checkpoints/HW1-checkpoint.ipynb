{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc87498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets evaluate scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4d1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Use this only after you check everything is being loaded properly\n",
    "\n",
    "import torch\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,\\\n",
    "    TrainingArguments, Trainer, pipeline, DataCollatorWithPadding, set_seed\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "# classifier(['this is a bad idea', 'I hate this so much'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25812ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99284ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dynasent (C:/Users/Jeonghoon Kim/.cache/huggingface/datasets/dynabench___dynasent/dynabench.dynasent.r1.all/1.1.0/ab89971d9ae1aacc59ed44d6855bf0e89167417257e2c2666f38e532148f2967)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89f3ba8da084092918e33adc3abfd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dynasent (C:/Users/Jeonghoon Kim/.cache/huggingface/datasets/dynabench___dynasent/dynabench.dynasent.r2.all/1.1.0/ab89971d9ae1aacc59ed44d6855bf0e89167417257e2c2666f38e532148f2967)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b708fd2fffe940f4b9e336171c47dd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r1_dataset = load_dataset(\"dynabench/dynasent\", \"dynabench.dynasent.r1.all\")\n",
    "\n",
    "r2_dataset = load_dataset(\"dynabench/dynasent\", \"dynabench.dynasent.r2.all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dce96da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
       "        num_rows: 80488\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
       "        num_rows: 3600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata'],\n",
       "        num_rows: 3600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15815c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'r1-0098060',\n",
       " 'hit_ids': ['y14605', 'y14606'],\n",
       " 'sentence': 'Had to remind him to toast the sandwich.',\n",
       " 'indices_into_review_text': [700, 740],\n",
       " 'model_0_label': 'positive',\n",
       " 'model_0_probs': {'negative': 0.011094148270785809,\n",
       "  'positive': 0.7560697793960571,\n",
       "  'neutral': 0.2328360378742218},\n",
       " 'text_id': 'r1-0098060',\n",
       " 'review_id': 'ebgPQgQJx5Al2CC-aNMU5A',\n",
       " 'review_rating': 1,\n",
       " 'label_distribution': {'positive': [],\n",
       "  'negative': ['w114', 'w380', 'w40', 'w516'],\n",
       "  'neutral': ['w1269'],\n",
       "  'mixed': []},\n",
       " 'gold_label': 'negative',\n",
       " 'metadata': {'split': 'test',\n",
       "  'round': 1,\n",
       "  'subset': 'all',\n",
       "  'model_in_the_loop': 'RoBERTa'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e6831e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'r2-0019256',\n",
       " 'hit_ids': ['y21512', 'y21524'],\n",
       " 'sentence': 'The art exhibit has a lot to offer.',\n",
       " 'sentence_author': 'w262',\n",
       " 'has_prompt': True,\n",
       " 'prompt_data': {'indices_into_review_text': [242, 356],\n",
       "  'review_rating': 5,\n",
       "  'prompt_sentence': \"They're currently under construction for a new exhibit, but there is still enough art to enjoy for around 2 hours.\",\n",
       "  'review_id': '0cJld_mdcScG6zZtoPEFTA'},\n",
       " 'model_1_label': 'positive',\n",
       " 'model_1_probs': {'negative': 0.010349077172577381,\n",
       "  'positive': 0.8954706788063049,\n",
       "  'neutral': 0.09418027848005295},\n",
       " 'text_id': 'r2-0019256',\n",
       " 'label_distribution': {'positive': ['w148', 'w358', 'w4', 'w423', 'w139'],\n",
       "  'negative': [],\n",
       "  'neutral': [],\n",
       "  'mixed': []},\n",
       " 'gold_label': 'positive',\n",
       " 'metadata': {'split': 'test',\n",
       "  'round': 2,\n",
       "  'subset': 'all',\n",
       "  'model_in_the_loop': 'RoBERTa'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29367be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r1_dataset = r1_dataset.rename_column('gold_label', 'label')\n",
    "# r2_dataset = r2_dataset.rename_column('gold_label', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c3c82",
   "metadata": {},
   "source": [
    "There are two fields in this dataset: \n",
    "\n",
    "- 'hit_ids': List of Amazon Mechanical Turk Human Interface Tasks (HITs) in which this example appeared during validation. The values are anonymized but used consistently throughout the dataset.\n",
    "- 'sentence': The example text.\n",
    "- 'indices_into_review_text': indices of 'sentence' into the original review in the Yelp Academic Dataset.\n",
    "- 'model_0_label': prediction of Model 0 as described in the paper. The possible values are 'positive', 'negative', and 'neutral'.\n",
    "- 'model_0_probs': probability distribution predicted by Model 0. The keys are ('positive', 'negative', 'neutral') and the values are floats.\n",
    "- 'text_id': unique identifier for this entry.\n",
    "- 'review_id': review-level identifier for the review from the Yelp Academic Dataset containing 'sentence'.\n",
    "- 'review_rating': review-level star-rating for the review containing 'sentence' in the Yelp Academic Dataset. The possible values are 1, 2, 3, 4, and 5.\n",
    "- 'label_distribution': response distribution from the MTurk validation task. The keys are ('positive', 'negative', 'neutral') and the values are lists of anonymized MTurk ids, which are used consistently throughout the dataset.\n",
    "- 'gold_label': the label chosen by at least three of the five workers if there is one (possible values: 'positive', 'negative', 'neutral', and 'mixed'), else None.\n",
    "\n",
    "- `sentence`: example sentence.\n",
    "- `gold_label`: string output `positive`, `negative`, `neutral` or `mixed`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24890c32",
   "metadata": {},
   "source": [
    "### 2. Preprocess\n",
    "\n",
    "The next step is to load a tokenizer to preprocess the `sentence` field.\n",
    "A tokenizer converts text to a sequence of tokens and creates numerical representation.\n",
    "Notice how there are multiple ways to tokenize text. Make sure to use the right tokenizer for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53607564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "distilbert-base-uncased\n",
      "['[CLS]', 'hello', 'mr', '.', 'kim', '!', '[SEP]']\n",
      "\n",
      "\n",
      "bert-base-cased\n",
      "['[CLS]', 'Hello', 'Mr', '.', 'Kim', '!', '[SEP]']\n",
      "\n",
      "\n",
      "roberta-base\n",
      "['<s>', 'Hello', 'Ä Mr', '.', 'Kim', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert_cased_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "text = \"Hello Mr.Kim!\"\n",
    "\n",
    "for tokenizer in [distilbert_tokenizer, bert_cased_tokenizer, roberta_tokenizer]:\n",
    "  print(f\"\\n\\n{tokenizer.name_or_path}\")\n",
    "  vocab = {v: k for k, v in tokenizer.vocab.items()}\n",
    "  tokenized_text = tokenizer(text)\n",
    "  print([vocab[id] for id in tokenized_text['input_ids']])\n",
    "    \n",
    "tokenizer = distilbert_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a5c4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee30f473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f71e59ac34e48949a893c6ace3ea5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9a4865e6af45218920ba7bb517fa91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec65eb0c3ee5405b94366086678958de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_r1_dataset = r1_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c920bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'hit_ids', 'sentence', 'indices_into_review_text', 'model_0_label', 'model_0_probs', 'text_id', 'review_id', 'review_rating', 'label_distribution', 'gold_label', 'metadata', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 80488\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_r1_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4738f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997470a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce04e7",
   "metadata": {},
   "source": [
    "### 3. Create evaluation method\n",
    "\n",
    "Including a metric during training is often helpful for evaluating your model's performance (otherwise, it just prints the loss). You can quickly load a evaluation method with the ðŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) metric (see the ðŸ¤— Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26d38612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of correct predictions among the total number of cases processed\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53367ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "#     print(predicitions, labels)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ce2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\"negative\": 0, \"positive\": 1, \"neutral\":2, \"mixed\": 3}\n",
    "label2id = {0: \"negative\", 1: \"positive\", 2:\"neutral\", 3:\"mixed\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf2e6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This automodel class gives us the model with pretrained weights + a sequence classification head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=4, id2label=id2label, label2id=label2id\n",
    ")\n",
    "class CustomTrainer(Trainer):\n",
    "    def _inner_training_loop(\n",
    "        self, batch_size=None, args=None, resume_from_checkpoint=None, trial=None, ignore_keys_for_eval=None\n",
    "    ):\n",
    "        number_of_epochs = args.num_train_epochs\n",
    "        start = time.time()\n",
    "        train_loss=[]\n",
    "        train_acc=[]\n",
    "        eval_acc=[]\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, 1, gamma=0.9)\n",
    "        \n",
    "        train_dataloader = self.get_train_dataloader()\n",
    "        eval_dataloader = self.get_eval_dataloader()\n",
    "\n",
    "        for epoch in range(number_of_epochs):\n",
    "            train_loss_per_epoch = 0\n",
    "            train_acc_per_epoch = 0\n",
    "            with tqdm(train_dataloader, unit=\"batch\") as training_epoch:\n",
    "                training_epoch.set_description(f\"Training Epoch {epoch}\")\n",
    "                print(training_epoch)\n",
    "                for step, inputs in enumerate(training_epoch):\n",
    "                    print(inputs)\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = inputs['labels']\n",
    "                    \n",
    "                    # forward pass\n",
    "                    self.optimizer.zero_grad()\n",
    "                    output = model(inputs['input_ids'])\n",
    "                    # get the loss\n",
    "                    loss = criterion(output['logits'], labels)\n",
    "                    train_loss_per_epoch += loss.item()\n",
    "                    #calculate gradients\n",
    "                    loss.backward()\n",
    "                    #update weights\n",
    "                    self.optimizer.step()\n",
    "                    train_acc_per_epoch += (output['logits'].argmax(1) == labels).sum().item()\n",
    "            # adjust the learning rate\n",
    "            self.scheduler.step()\n",
    "            train_loss_per_epoch /= len(train_dataloader)\n",
    "            train_acc_per_epoch /= (len(train_dataloader)*batch_size)\n",
    "            \n",
    "            \n",
    "            eval_loss_per_epoch = 0\n",
    "            eval_acc_per_epoch = 0\n",
    "            with tqdm(eval_dataloader, unit=\"batch\") as eval_epoch:\n",
    "                eval_epoch.set_description(f\"Evaluation Epoch {epoch}\")\n",
    "                for step, inputs in enumerate(eval_epoch):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = inputs['labels']\n",
    "                    with torch.no_grad():\n",
    "                        output = model(inputs['input_ids'])\n",
    "                        loss = criterion(output['logits'], labels)\n",
    "                        eval_loss_per_epoch += loss.item()\n",
    "                        eval_acc_per_epoch += (output['logits'].argmax(1) == labels).sum().item()\n",
    "            eval_loss_per_epoch /= (len(eval_dataloader))\n",
    "            eval_acc_per_epoch /= (len(eval_dataloader)*batch_size)\n",
    "        \n",
    "            \n",
    "            print(f'\\tTrain Loss: {train_loss_per_epoch:.3f} | Train Acc: {train_acc_per_epoch*100:.2f}%')\n",
    "            print(f'\\tEval Loss: {eval_loss_per_epoch:.3f} | Eval Acc: {eval_acc_per_epoch*100:.2f}%')\n",
    "    \n",
    "        print(f'Time: {(time.time()-start)/60:.3f} minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d5d0df2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0:   0%|                                                                    | 0/2516 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0:   0%|                                                                    | 0/2516 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 25\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(training_args)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# https://huggingface.co/transformers/v4.4.2/main_classes/trainer.html#id1\u001b[39;00m\n\u001b[0;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\transformers\\trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1540\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1542\u001b[0m )\n\u001b[1;32m-> 1543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [22], line 30\u001b[0m, in \u001b[0;36mCustomTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_epoch):\n\u001b[0;32m     29\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 30\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:237\u001b[0m, in \u001b[0;36mBatchEncoding.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03mIf the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03metc.).\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03mIf the key is an integer, get the `tokenizers.Encoding` for batch item with index `key`.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings[item]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'labels'"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/transformers/v4.4.2/main_classes/trainer.html#trainingarguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "# print(training_args)\n",
    "# https://huggingface.co/transformers/v4.4.2/main_classes/trainer.html#id1\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_r1_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_r1_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b748de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af38289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19682ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6c20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466a1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1d9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78708721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
